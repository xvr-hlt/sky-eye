{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/xvr-hlt/uncategorized\" target=\"_blank\">https://app.wandb.ai/xvr-hlt/uncategorized</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/xvr-hlt/uncategorized/runs/5tu8pc0o\" target=\"_blank\">https://app.wandb.ai/xvr-hlt/uncategorized/runs/5tu8pc0o</a><br/>\n",
       "                Docs: <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">https://docs.wandb.com/integrations/jupyter.html</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "W&B Run: https://app.wandb.ai/xvr-hlt/uncategorized/runs/5tu8pc0o"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "import os\n",
    "#os.environ['WANDB_MODE'] = 'dryrun'\n",
    "wandb.init(\"sky-eye-full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = '/home/jupyter/datasets/xview/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import itertools\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "from detectron2.structures import BoxMode\n",
    "import shapely.wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "damage_classes = ('no-damage', 'minor-damage', 'major-damage', 'destroyed')\n",
    "damage_cat_ids = {i:ix for ix, i in enumerate(damage_classes)}\n",
    "\n",
    "def get_instances(files, bbox_mode=detectron2.structures.boxes.BoxMode.XYXY_ABS, thresh=1000):\n",
    "    dataset_dicts = []\n",
    "    for file in tqdm(files):\n",
    "        with open(file) as f:\n",
    "            i = json.load(f)\n",
    "        if len(i['features']['xy']) > thresh:\n",
    "            continue\n",
    "\n",
    "        h,w = i['metadata']['height'], i['metadata']['width']\n",
    "        objs = []\n",
    "        \n",
    "        for feat in i['features']['xy']:\n",
    "            prop = feat['properties']\n",
    "            if prop.get('subtype') == 'un-classified':\n",
    "                continue\n",
    "            poly = shapely.wkt.loads(feat['wkt'])\n",
    "            points = list(poly.exterior.coords)\n",
    "            px, py = zip(*points)\n",
    "            segm = [p for xy in points for p in xy]\n",
    "            \n",
    "            objs.append({\n",
    "                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
    "                \"bbox_mode\": bbox_mode,\n",
    "                \"segmentation\": [segm],\n",
    "                \"category_id\": damage_cat_ids[prop['subtype']] if 'subtype' in prop else 0,\n",
    "                \"iscrowd\": 0\n",
    "            })\n",
    "\n",
    "        dataset_dicts.append({\n",
    "            'height': h,\n",
    "            'width': w,\n",
    "            'file_name': file.replace('/labels/', '/images/').replace('json', 'png'),\n",
    "            'annotations': objs\n",
    "        })\n",
    "    return dataset_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "\n",
    "for typ, thing_classes in (('pre', ('building',)), ('post', damage_classes)):\n",
    "    random.seed(0)\n",
    "    all_files = glob(f'{TRAIN_DIR}/labels/*{typ}_disaster.json')\n",
    "    dev_ix = int(len(all_files)*.20)\n",
    "    dev_instances = all_files[:dev_ix]\n",
    "    train_instances = all_files[dev_ix:]\n",
    "    \n",
    "    DatasetCatalog.register(f\"{typ}/train\", lambda i=train_instances: get_instances(i))\n",
    "    MetadataCatalog.get(f\"{typ}/train\").set(thing_classes=thing_classes)\n",
    "    \n",
    "    DatasetCatalog.register(f\"{typ}/dev\", lambda i=dev_instances: get_instances(i))\n",
    "    MetadataCatalog.get(f\"{typ}/dev\").set(thing_classes=thing_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56fb52610a0a47e8b665347866c5dd6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=559), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = 'post'\n",
    "dataset_train = f'{dataset}/train'\n",
    "dataset_dev = f'{dataset}/dev'\n",
    "dev_dicts = DatasetCatalog.get(dataset_dev)\n",
    "metadata = MetadataCatalog.get(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import detectron2.data.transforms as T\n",
    "from detectron2.structures.masks import polygons_to_bitmask\n",
    "from random import sample\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from PIL import Image\n",
    "\n",
    "#dev_dicts = get_instances(dev_instances)\n",
    "\n",
    "def sample_vis(model, cfg, dicts, n=5):\n",
    "    model = model.eval()\n",
    "    transform_gen = T.ResizeShortestEdge([cfg.INPUT.MIN_SIZE_TEST, cfg.INPUT.MIN_SIZE_TEST], cfg.INPUT.MAX_SIZE_TEST)\n",
    "    input_format = cfg.INPUT.FORMAT\n",
    "    images = []\n",
    "    for d in sample(dicts, n):\n",
    "        with torch.no_grad():\n",
    "            im = cv2.imread(d[\"file_name\"])\n",
    "            inputs = prepare_inputs(im, input_format, transform_gen)\n",
    "            outputs = model([inputs])[0]\n",
    "\n",
    "    \n",
    "            vis = Visualizer(im[:, :, ::-1],\n",
    "                           metadata=metadata, \n",
    "                           scale=0.5, \n",
    "                           #instance_mode=ColorMode.IMAGE_BW\n",
    "            )\n",
    "            pred = vis.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "            images.append(Image.fromarray(pred.get_image()))\n",
    "    model.train()\n",
    "    wandb.log({'examples': [wandb.Image(i) for i in images]})\n",
    "    return {'metric': 1}\n",
    "\n",
    "def prepare_inputs(original_image, input_format, transform_gen):\n",
    "    if input_format == \"RGB\":\n",
    "        original_image = original_image[:, :, ::-1]\n",
    "    height, width = original_image.shape[:2]\n",
    "    image = transform_gen.get_transform(original_image).apply_image(original_image)\n",
    "    image = torch.as_tensor(image.astype(\"float32\").transpose(2, 0, 1))\n",
    "    return {\"image\": image, \"height\": height, \"width\": width}\n",
    "\n",
    "def eval_model(eval_dicts, cfg, model):\n",
    "    model = model.eval()\n",
    "    transform_gen = T.ResizeShortestEdge([cfg.INPUT.MIN_SIZE_TEST, cfg.INPUT.MIN_SIZE_TEST], cfg.INPUT.MAX_SIZE_TEST)\n",
    "    input_format = cfg.INPUT.FORMAT\n",
    "    tps, fns, fps = 0., 0., 0.\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for e in tqdm(eval_dicts):\n",
    "            im = cv2.imread(e[\"file_name\"])\n",
    "            inputs = prepare_inputs(im, input_format, transform_gen)\n",
    "            outputs = model([inputs])[0]\n",
    "            outputs_bool = np.array(outputs['instances'].pred_masks.cpu()).sum(0) > 0\n",
    "            polygons = [np.array(a['segmentation'][0]) for a in e['annotations']]\n",
    "            if len(polygons) > 0:\n",
    "                targets_bool = polygons_to_bitmask(polygons, e['height'], e['width'])\n",
    "            else:\n",
    "                targets_bool = np.zeros((1024,1024)).astype(np.bool)\n",
    "\n",
    "            tps += outputs_bool[targets_bool].sum() if targets_bool.sum() > 0 else 0.\n",
    "            fns += targets_bool[~outputs_bool].sum() if (~outputs_bool).sum() > 0 else 0.\n",
    "            fps += (~targets_bool[outputs_bool]).sum() if outputs_bool.sum() > 0 else 0.\n",
    "    \n",
    "    rec = tps/(tps+fns)\n",
    "    pre = tps/(tps+fps)\n",
    "    metrics = {\n",
    "        'building:recall': rec,\n",
    "        'building:precision': pre,\n",
    "        'building:f1': 2*rec*pre/(rec+pre)\n",
    "    }\n",
    "    wandb.log(metrics)\n",
    "    model = model.train()\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "nbatches = len(train_instances) // batch_size\n",
    "epochs = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/30 11:38:24 d2.config.compat]: \u001b[0mConfig 'detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "\u001b[32m[10/30 11:38:28 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=16, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (predictor): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb148c69d84141028262f10e4f185e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2240), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m[10/30 11:38:40 d2.data.build]: \u001b[0mDistribution of training instances among all 4 categories:\n",
      "\u001b[36m|  category  | #instances   |   category   | #instances   |   category   | #instances   |\n",
      "|:----------:|:-------------|:------------:|:-------------|:------------:|:-------------|\n",
      "| no-damage  | 88355        | minor-damage | 12350        | major-damage | 11841        |\n",
      "| destroyed  | 8595         |              |              |              |              |\n",
      "|   total    | 121141       |              |              |              |              |\u001b[0m\n",
      "\u001b[32m[10/30 11:38:40 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(512, 768, 1024), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[10/30 11:38:40 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'roi_heads.box_predictor.cls_score.weight' has shape (81, 1024) in the checkpoint but (5, 1024) in the model! Skipped.\n",
      "'roi_heads.box_predictor.cls_score.bias' has shape (81,) in the checkpoint but (5,) in the model! Skipped.\n",
      "'roi_heads.box_predictor.bbox_pred.weight' has shape (320, 1024) in the checkpoint but (16, 1024) in the model! Skipped.\n",
      "'roi_heads.box_predictor.bbox_pred.bias' has shape (320,) in the checkpoint but (16,) in the model! Skipped.\n",
      "'roi_heads.mask_head.predictor.weight' has shape (80, 256, 1, 1) in the checkpoint but (4, 256, 1, 1) in the model! Skipped.\n",
      "'roi_heads.mask_head.predictor.bias' has shape (80,) in the checkpoint but (4,) in the model! Skipped.\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "import os\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\")\n",
    "cfg.DATASETS.TRAIN = (dataset_train,)\n",
    "cfg.DATASETS.TEST = ()\n",
    "\n",
    "cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = False\n",
    "cfg.DATALOADER.NUM_WORKERS = 8\n",
    "\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = nbatches*10\n",
    "cfg.SOLVER.MAX_ITER = nbatches*epochs\n",
    "cfg.STEPS = cfg.SOLVER.MAX_ITER*.85, cfg.SOLVER.MAX_ITER*.15\n",
    "\n",
    "cfg.INPUT.CROP.ENABLED = True\n",
    "cfg.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x/138205316/model_final_a3ec72.pkl\"  # initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = batch_size\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(metadata.thing_classes)\n",
    "cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[8], [16], [32], [64], [128]]\n",
    "\n",
    "cfg.INPUT.MIN_SIZE_TRAIN = (512, 768, 1024)\n",
    "cfg.MIN_SIZE_TRAIN_SAMPLING = \"choice\"\n",
    "\n",
    "cfg.TEST.AUG.ENABLED = True\n",
    "cfg.TEST.AUG.MIN_SIZES = (512, 768, 1024)\n",
    "cfg.TEST.AUG.FLIP = True\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
    "\n",
    "\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/30 11:38:41 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/30 11:38:51 d2.utils.events]: \u001b[0meta: 11:37:18  iter: 19  total_loss: 5.070  loss_cls: 1.756  loss_box_reg: 0.168  loss_mask: 0.693  loss_rpn_cls: 2.135  loss_rpn_loc: 0.338  time: 0.4598  data_time: 0.0114  lr: 0.000005  max_mem: 4836M\n",
      "\u001b[32m[10/30 11:39:00 d2.utils.events]: \u001b[0meta: 11:37:09  iter: 39  total_loss: 4.289  loss_cls: 1.584  loss_box_reg: 0.203  loss_mask: 0.692  loss_rpn_cls: 1.507  loss_rpn_loc: 0.312  time: 0.4555  data_time: 0.0035  lr: 0.000010  max_mem: 6898M\n",
      "\u001b[32m[10/30 11:39:09 d2.utils.events]: \u001b[0meta: 11:24:26  iter: 59  total_loss: 2.880  loss_cls: 1.300  loss_box_reg: 0.167  loss_mask: 0.690  loss_rpn_cls: 0.503  loss_rpn_loc: 0.323  time: 0.4493  data_time: 0.0040  lr: 0.000015  max_mem: 6898M\n",
      "\u001b[32m[10/30 11:39:18 d2.utils.events]: \u001b[0meta: 11:38:08  iter: 79  total_loss: 2.357  loss_cls: 0.986  loss_box_reg: 0.109  loss_mask: 0.684  loss_rpn_cls: 0.318  loss_rpn_loc: 0.312  time: 0.4493  data_time: 0.0030  lr: 0.000020  max_mem: 6898M\n",
      "\u001b[32m[10/30 11:39:26 d2.utils.events]: \u001b[0meta: 11:22:11  iter: 99  total_loss: 2.169  loss_cls: 0.680  loss_box_reg: 0.128  loss_mask: 0.681  loss_rpn_cls: 0.257  loss_rpn_loc: 0.324  time: 0.4452  data_time: 0.0046  lr: 0.000025  max_mem: 6898M\n",
      "\u001b[32m[10/30 11:39:35 d2.utils.events]: \u001b[0meta: 11:25:17  iter: 119  total_loss: 1.876  loss_cls: 0.519  loss_box_reg: 0.120  loss_mask: 0.668  loss_rpn_cls: 0.216  loss_rpn_loc: 0.296  time: 0.4458  data_time: 0.0070  lr: 0.000030  max_mem: 6898M\n",
      "\u001b[32m[10/30 11:39:45 d2.utils.events]: \u001b[0meta: 11:34:10  iter: 139  total_loss: 2.280  loss_cls: 0.569  loss_box_reg: 0.213  loss_mask: 0.661  loss_rpn_cls: 0.309  loss_rpn_loc: 0.489  time: 0.4524  data_time: 0.0046  lr: 0.000035  max_mem: 6898M\n",
      "\u001b[32m[10/30 11:39:54 d2.utils.events]: \u001b[0meta: 11:28:13  iter: 159  total_loss: 1.751  loss_cls: 0.395  loss_box_reg: 0.186  loss_mask: 0.647  loss_rpn_cls: 0.182  loss_rpn_loc: 0.340  time: 0.4494  data_time: 0.0049  lr: 0.000040  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:40:03 d2.utils.events]: \u001b[0meta: 11:30:26  iter: 179  total_loss: 2.127  loss_cls: 0.500  loss_box_reg: 0.232  loss_mask: 0.632  loss_rpn_cls: 0.214  loss_rpn_loc: 0.385  time: 0.4527  data_time: 0.0051  lr: 0.000045  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:40:12 d2.utils.events]: \u001b[0meta: 11:33:42  iter: 199  total_loss: 1.724  loss_cls: 0.409  loss_box_reg: 0.166  loss_mask: 0.628  loss_rpn_cls: 0.190  loss_rpn_loc: 0.312  time: 0.4525  data_time: 0.0047  lr: 0.000050  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:40:22 d2.utils.events]: \u001b[0meta: 11:37:31  iter: 219  total_loss: 1.998  loss_cls: 0.495  loss_box_reg: 0.239  loss_mask: 0.611  loss_rpn_cls: 0.245  loss_rpn_loc: 0.362  time: 0.4545  data_time: 0.0064  lr: 0.000055  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:40:30 d2.utils.events]: \u001b[0meta: 11:27:36  iter: 239  total_loss: 1.674  loss_cls: 0.412  loss_box_reg: 0.217  loss_mask: 0.602  loss_rpn_cls: 0.167  loss_rpn_loc: 0.290  time: 0.4525  data_time: 0.0042  lr: 0.000060  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:40:39 d2.utils.events]: \u001b[0meta: 11:25:35  iter: 259  total_loss: 1.701  loss_cls: 0.406  loss_box_reg: 0.266  loss_mask: 0.600  loss_rpn_cls: 0.130  loss_rpn_loc: 0.349  time: 0.4503  data_time: 0.0032  lr: 0.000065  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:40:48 d2.utils.events]: \u001b[0meta: 11:24:57  iter: 279  total_loss: 1.686  loss_cls: 0.360  loss_box_reg: 0.238  loss_mask: 0.583  loss_rpn_cls: 0.161  loss_rpn_loc: 0.270  time: 0.4488  data_time: 0.0058  lr: 0.000070  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:40:57 d2.utils.events]: \u001b[0meta: 11:25:38  iter: 299  total_loss: 1.755  loss_cls: 0.358  loss_box_reg: 0.230  loss_mask: 0.575  loss_rpn_cls: 0.193  loss_rpn_loc: 0.376  time: 0.4509  data_time: 0.0056  lr: 0.000075  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:41:06 d2.utils.events]: \u001b[0meta: 11:25:08  iter: 319  total_loss: 1.539  loss_cls: 0.389  loss_box_reg: 0.215  loss_mask: 0.567  loss_rpn_cls: 0.141  loss_rpn_loc: 0.275  time: 0.4505  data_time: 0.0035  lr: 0.000080  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:41:15 d2.utils.events]: \u001b[0meta: 11:24:58  iter: 339  total_loss: 1.613  loss_cls: 0.318  loss_box_reg: 0.202  loss_mask: 0.555  loss_rpn_cls: 0.124  loss_rpn_loc: 0.323  time: 0.4498  data_time: 0.0037  lr: 0.000085  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:41:23 d2.utils.events]: \u001b[0meta: 11:22:40  iter: 359  total_loss: 1.694  loss_cls: 0.359  loss_box_reg: 0.187  loss_mask: 0.549  loss_rpn_cls: 0.174  loss_rpn_loc: 0.331  time: 0.4485  data_time: 0.0048  lr: 0.000090  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:41:33 d2.utils.events]: \u001b[0meta: 11:23:16  iter: 379  total_loss: 1.541  loss_cls: 0.373  loss_box_reg: 0.242  loss_mask: 0.555  loss_rpn_cls: 0.133  loss_rpn_loc: 0.238  time: 0.4489  data_time: 0.0042  lr: 0.000095  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:41:41 d2.utils.events]: \u001b[0meta: 11:21:59  iter: 399  total_loss: 1.631  loss_cls: 0.327  loss_box_reg: 0.233  loss_mask: 0.525  loss_rpn_cls: 0.153  loss_rpn_loc: 0.314  time: 0.4483  data_time: 0.0056  lr: 0.000100  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:41:51 d2.utils.events]: \u001b[0meta: 11:22:13  iter: 419  total_loss: 1.591  loss_cls: 0.336  loss_box_reg: 0.295  loss_mask: 0.501  loss_rpn_cls: 0.213  loss_rpn_loc: 0.314  time: 0.4489  data_time: 0.0054  lr: 0.000105  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:42:00 d2.utils.events]: \u001b[0meta: 11:22:04  iter: 439  total_loss: 1.639  loss_cls: 0.350  loss_box_reg: 0.317  loss_mask: 0.508  loss_rpn_cls: 0.138  loss_rpn_loc: 0.356  time: 0.4489  data_time: 0.0046  lr: 0.000110  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:42:10 d2.utils.events]: \u001b[0meta: 11:28:16  iter: 459  total_loss: 1.453  loss_cls: 0.292  loss_box_reg: 0.220  loss_mask: 0.491  loss_rpn_cls: 0.133  loss_rpn_loc: 0.314  time: 0.4511  data_time: 0.0044  lr: 0.000115  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:42:18 d2.utils.events]: \u001b[0meta: 11:23:54  iter: 479  total_loss: 1.570  loss_cls: 0.375  loss_box_reg: 0.250  loss_mask: 0.491  loss_rpn_cls: 0.159  loss_rpn_loc: 0.337  time: 0.4494  data_time: 0.0038  lr: 0.000120  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:42:26 d2.utils.events]: \u001b[0meta: 11:21:36  iter: 499  total_loss: 1.570  loss_cls: 0.390  loss_box_reg: 0.293  loss_mask: 0.498  loss_rpn_cls: 0.144  loss_rpn_loc: 0.258  time: 0.4483  data_time: 0.0028  lr: 0.000125  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:42:36 d2.utils.events]: \u001b[0meta: 11:22:12  iter: 519  total_loss: 1.782  loss_cls: 0.427  loss_box_reg: 0.320  loss_mask: 0.457  loss_rpn_cls: 0.162  loss_rpn_loc: 0.335  time: 0.4490  data_time: 0.0064  lr: 0.000130  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:42:45 d2.utils.events]: \u001b[0meta: 11:23:48  iter: 539  total_loss: 1.745  loss_cls: 0.417  loss_box_reg: 0.253  loss_mask: 0.519  loss_rpn_cls: 0.153  loss_rpn_loc: 0.346  time: 0.4504  data_time: 0.0063  lr: 0.000135  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:42:54 d2.utils.events]: \u001b[0meta: 11:23:39  iter: 559  total_loss: 1.444  loss_cls: 0.353  loss_box_reg: 0.204  loss_mask: 0.481  loss_rpn_cls: 0.120  loss_rpn_loc: 0.202  time: 0.4503  data_time: 0.0042  lr: 0.000140  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:43:03 d2.utils.events]: \u001b[0meta: 11:22:39  iter: 579  total_loss: 2.086  loss_cls: 0.435  loss_box_reg: 0.338  loss_mask: 0.484  loss_rpn_cls: 0.163  loss_rpn_loc: 0.404  time: 0.4495  data_time: 0.0052  lr: 0.000145  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:43:12 d2.utils.events]: \u001b[0meta: 11:23:20  iter: 599  total_loss: 1.664  loss_cls: 0.423  loss_box_reg: 0.319  loss_mask: 0.461  loss_rpn_cls: 0.129  loss_rpn_loc: 0.299  time: 0.4498  data_time: 0.0037  lr: 0.000150  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:43:22 d2.utils.events]: \u001b[0meta: 11:26:13  iter: 619  total_loss: 1.551  loss_cls: 0.361  loss_box_reg: 0.232  loss_mask: 0.499  loss_rpn_cls: 0.136  loss_rpn_loc: 0.321  time: 0.4508  data_time: 0.0029  lr: 0.000155  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:43:31 d2.utils.events]: \u001b[0meta: 11:26:44  iter: 639  total_loss: 1.746  loss_cls: 0.379  loss_box_reg: 0.296  loss_mask: 0.467  loss_rpn_cls: 0.169  loss_rpn_loc: 0.289  time: 0.4508  data_time: 0.0054  lr: 0.000160  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:43:39 d2.utils.events]: \u001b[0meta: 11:23:34  iter: 659  total_loss: 1.396  loss_cls: 0.317  loss_box_reg: 0.235  loss_mask: 0.467  loss_rpn_cls: 0.087  loss_rpn_loc: 0.308  time: 0.4501  data_time: 0.0042  lr: 0.000165  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:43:48 d2.utils.events]: \u001b[0meta: 11:22:22  iter: 679  total_loss: 1.870  loss_cls: 0.462  loss_box_reg: 0.365  loss_mask: 0.444  loss_rpn_cls: 0.154  loss_rpn_loc: 0.400  time: 0.4494  data_time: 0.0045  lr: 0.000170  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:43:57 d2.utils.events]: \u001b[0meta: 11:22:34  iter: 699  total_loss: 1.742  loss_cls: 0.450  loss_box_reg: 0.346  loss_mask: 0.452  loss_rpn_cls: 0.163  loss_rpn_loc: 0.396  time: 0.4495  data_time: 0.0066  lr: 0.000175  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:44:06 d2.utils.events]: \u001b[0meta: 11:23:30  iter: 719  total_loss: 1.545  loss_cls: 0.322  loss_box_reg: 0.248  loss_mask: 0.464  loss_rpn_cls: 0.121  loss_rpn_loc: 0.327  time: 0.4501  data_time: 0.0043  lr: 0.000180  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:44:15 d2.utils.events]: \u001b[0meta: 11:22:52  iter: 739  total_loss: 1.562  loss_cls: 0.338  loss_box_reg: 0.302  loss_mask: 0.463  loss_rpn_cls: 0.130  loss_rpn_loc: 0.314  time: 0.4497  data_time: 0.0043  lr: 0.000185  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:44:24 d2.utils.events]: \u001b[0meta: 11:23:12  iter: 759  total_loss: 1.933  loss_cls: 0.460  loss_box_reg: 0.395  loss_mask: 0.455  loss_rpn_cls: 0.142  loss_rpn_loc: 0.363  time: 0.4501  data_time: 0.0049  lr: 0.000190  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:44:33 d2.utils.events]: \u001b[0meta: 11:21:57  iter: 779  total_loss: 1.524  loss_cls: 0.346  loss_box_reg: 0.316  loss_mask: 0.427  loss_rpn_cls: 0.126  loss_rpn_loc: 0.279  time: 0.4497  data_time: 0.0056  lr: 0.000195  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:44:42 d2.utils.events]: \u001b[0meta: 11:22:53  iter: 799  total_loss: 1.335  loss_cls: 0.339  loss_box_reg: 0.307  loss_mask: 0.418  loss_rpn_cls: 0.101  loss_rpn_loc: 0.233  time: 0.4502  data_time: 0.0038  lr: 0.000200  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:44:52 d2.utils.events]: \u001b[0meta: 11:22:44  iter: 819  total_loss: 1.973  loss_cls: 0.462  loss_box_reg: 0.378  loss_mask: 0.431  loss_rpn_cls: 0.144  loss_rpn_loc: 0.359  time: 0.4504  data_time: 0.0041  lr: 0.000205  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:45:01 d2.utils.events]: \u001b[0meta: 11:24:06  iter: 839  total_loss: 1.767  loss_cls: 0.434  loss_box_reg: 0.317  loss_mask: 0.424  loss_rpn_cls: 0.136  loss_rpn_loc: 0.330  time: 0.4509  data_time: 0.0053  lr: 0.000210  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:45:11 d2.utils.events]: \u001b[0meta: 11:25:26  iter: 859  total_loss: 1.641  loss_cls: 0.397  loss_box_reg: 0.346  loss_mask: 0.455  loss_rpn_cls: 0.119  loss_rpn_loc: 0.306  time: 0.4523  data_time: 0.0039  lr: 0.000215  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:45:21 d2.utils.events]: \u001b[0meta: 11:26:02  iter: 879  total_loss: 1.729  loss_cls: 0.429  loss_box_reg: 0.304  loss_mask: 0.453  loss_rpn_cls: 0.109  loss_rpn_loc: 0.360  time: 0.4526  data_time: 0.0061  lr: 0.000220  max_mem: 7168M\n",
      "\u001b[32m[10/30 11:45:30 d2.utils.events]: \u001b[0meta: 11:27:13  iter: 899  total_loss: 1.687  loss_cls: 0.371  loss_box_reg: 0.253  loss_mask: 0.424  loss_rpn_cls: 0.135  loss_rpn_loc: 0.304  time: 0.4532  data_time: 0.0043  lr: 0.000225  max_mem: 7641M\n",
      "\u001b[32m[10/30 11:45:40 d2.utils.events]: \u001b[0meta: 11:28:45  iter: 919  total_loss: 1.747  loss_cls: 0.391  loss_box_reg: 0.352  loss_mask: 0.461  loss_rpn_cls: 0.138  loss_rpn_loc: 0.270  time: 0.4535  data_time: 0.0041  lr: 0.000230  max_mem: 7641M\n",
      "\u001b[32m[10/30 11:45:49 d2.utils.events]: \u001b[0meta: 11:26:55  iter: 939  total_loss: 1.533  loss_cls: 0.397  loss_box_reg: 0.333  loss_mask: 0.408  loss_rpn_cls: 0.111  loss_rpn_loc: 0.323  time: 0.4536  data_time: 0.0029  lr: 0.000235  max_mem: 7641M\n",
      "\u001b[32m[10/30 11:45:58 d2.utils.events]: \u001b[0meta: 11:25:35  iter: 959  total_loss: 1.493  loss_cls: 0.399  loss_box_reg: 0.351  loss_mask: 0.437  loss_rpn_cls: 0.134  loss_rpn_loc: 0.237  time: 0.4537  data_time: 0.0038  lr: 0.000240  max_mem: 7641M\n",
      "\u001b[32m[10/30 11:46:08 d2.utils.events]: \u001b[0meta: 11:25:40  iter: 979  total_loss: 1.848  loss_cls: 0.415  loss_box_reg: 0.426  loss_mask: 0.433  loss_rpn_cls: 0.158  loss_rpn_loc: 0.302  time: 0.4543  data_time: 0.0066  lr: 0.000245  max_mem: 7641M\n",
      "\u001b[32m[10/30 11:46:17 d2.utils.events]: \u001b[0meta: 11:26:27  iter: 999  total_loss: 1.662  loss_cls: 0.444  loss_box_reg: 0.404  loss_mask: 0.421  loss_rpn_cls: 0.142  loss_rpn_loc: 0.371  time: 0.4548  data_time: 0.0056  lr: 0.000250  max_mem: 8039M\n",
      "\u001b[32m[10/30 11:46:26 d2.utils.events]: \u001b[0meta: 11:26:18  iter: 1019  total_loss: 1.823  loss_cls: 0.356  loss_box_reg: 0.312  loss_mask: 0.422  loss_rpn_cls: 0.119  loss_rpn_loc: 0.342  time: 0.4549  data_time: 0.0039  lr: 0.000250  max_mem: 8219M\n",
      "\u001b[32m[10/30 11:46:36 d2.utils.events]: \u001b[0meta: 11:27:16  iter: 1039  total_loss: 1.602  loss_cls: 0.414  loss_box_reg: 0.352  loss_mask: 0.467  loss_rpn_cls: 0.130  loss_rpn_loc: 0.313  time: 0.4550  data_time: 0.0047  lr: 0.000250  max_mem: 8219M\n",
      "\u001b[32m[10/30 11:46:45 d2.utils.events]: \u001b[0meta: 11:25:59  iter: 1059  total_loss: 1.983  loss_cls: 0.457  loss_box_reg: 0.458  loss_mask: 0.437  loss_rpn_cls: 0.130  loss_rpn_loc: 0.395  time: 0.4549  data_time: 0.0035  lr: 0.000250  max_mem: 8219M\n",
      "\u001b[32m[10/30 11:46:54 d2.utils.events]: \u001b[0meta: 11:24:39  iter: 1079  total_loss: 1.411  loss_cls: 0.289  loss_box_reg: 0.286  loss_mask: 0.450  loss_rpn_cls: 0.096  loss_rpn_loc: 0.224  time: 0.4547  data_time: 0.0038  lr: 0.000250  max_mem: 8219M\n",
      "\u001b[32m[10/30 11:47:03 d2.utils.events]: \u001b[0meta: 11:27:12  iter: 1099  total_loss: 1.546  loss_cls: 0.431  loss_box_reg: 0.368  loss_mask: 0.428  loss_rpn_cls: 0.134  loss_rpn_loc: 0.326  time: 0.4548  data_time: 0.0043  lr: 0.000250  max_mem: 8219M\n",
      "\u001b[32m[10/30 11:47:12 d2.utils.events]: \u001b[0meta: 11:27:50  iter: 1119  total_loss: 1.530  loss_cls: 0.317  loss_box_reg: 0.337  loss_mask: 0.440  loss_rpn_cls: 0.113  loss_rpn_loc: 0.314  time: 0.4550  data_time: 0.0050  lr: 0.000250  max_mem: 8219M\n",
      "\u001b[32m[10/30 11:47:15 d2.engine.hooks]: \u001b[0mOverall training speed: 1117 iterations in 0:08:28 (0.4555 s / it)\n",
      "\u001b[32m[10/30 11:47:15 d2.engine.hooks]: \u001b[0mTotal training time: 0:08:32 (0:00:04 on hooks)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Eval function must return a dict. Got [<PIL.Image.Image image mode=RGB size=512x512 at 0x7FBE0AE85E50>, <PIL.Image.Image image mode=RGB size=512x512 at 0x7FBD38301D10>, <PIL.Image.Image image mode=RGB size=512x512 at 0x7FBD382C3890>, <PIL.Image.Image image mode=RGB size=512x512 at 0x7FBD38297310>, <PIL.Image.Image image mode=RGB size=512x512 at 0x7FBD382B0410>] instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c786eafcb23d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mvis_hook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvalHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msample_vis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_dicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvis_hook\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mOrderedDict\u001b[0m \u001b[0mof\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0menabled\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mOtherwise\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \"\"\"\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_last_eval_results\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_main_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mverify_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_eval_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/detectron2/engine/train_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, start_iter, max_iter)\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/detectron2/engine/train_loop.py\u001b[0m in \u001b[0;36mafter_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mafter_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;31m# this guarantees, that in each hook's after_step, storage.iter == trainer.iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/detectron2/engine/hooks.py\u001b[0m in \u001b[0;36mafter_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    313\u001b[0m                 assert isinstance(\n\u001b[1;32m    314\u001b[0m                     \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m                 ), \"Eval function must return a dict. Got {} instead.\".format(results)\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                 \u001b[0mflattened_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_results_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Eval function must return a dict. Got [<PIL.Image.Image image mode=RGB size=512x512 at 0x7FBE0AE85E50>, <PIL.Image.Image image mode=RGB size=512x512 at 0x7FBD38301D10>, <PIL.Image.Image image mode=RGB size=512x512 at 0x7FBD382C3890>, <PIL.Image.Image image mode=RGB size=512x512 at 0x7FBD38297310>, <PIL.Image.Image image mode=RGB size=512x512 at 0x7FBD382B0410>] instead."
     ]
    }
   ],
   "source": [
    "train_model=True\n",
    "if train_model:\n",
    "    from detectron2.engine.hooks import EvalHook\n",
    "\n",
    "    # evaluate every 2 epochs\n",
    "\n",
    "    #eval_hook = EvalHook(1*nbatches, lambda: eval_model(dev_dicts, cfg, trainer.model))\n",
    "    vis_hook = EvalHook(nbatches, lambda: sample_vis(trainer.model, cfg, dev_dicts))\n",
    "    trainer.register_hooks([vis_hook])\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3\n",
    "cfg.DATASETS.TEST = (\"buildings/dev\", )\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.structures.masks import polygons_to_bitmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in random.sample(dev_data, 3):    \n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)\n",
    "    \n",
    "    vis = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=building_metadata, \n",
    "                   scale=0.5, \n",
    "                   #instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    "    )\n",
    "    display(\"Pred\")\n",
    "    pred = vis.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    display(Image.fromarray(pred.get_image()))\n",
    "    \n",
    "    vis = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=building_metadata, \n",
    "                   scale=0.5, \n",
    "                   #instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    "    )\n",
    "    \n",
    "    display(\"Target\")\n",
    "    target = vis.draw_dataset_dict(d)\n",
    "    display(Image.fromarray(target.get_image()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dicts = dataset_dicts = get_pre_dataset(train_instances)\n",
    "import random\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "for d in random.sample(dataset_dicts, 3):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=building_metadata, scale=.5)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    display(Image.fromarray(vis.get_image()))(train_instances)\n",
    "import random\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "for d in random.sample(dataset_dicts, 3):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=building_metadata, scale=.5)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    display(Image.fromarray(vis.get_image()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(eval_dicts, cfg, model):\n",
    "    model = model.eval()\n",
    "    transform_gen = T.ResizeShortestEdge([cfg.INPUT.MIN_SIZE_TEST, cfg.INPUT.MIN_SIZE_TEST], cfg.INPUT.MAX_SIZE_TEST)\n",
    "    input_format = cfg.INPUT.FORMAT\n",
    "    tps, fns, fps = 0., 0., 0.\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for e in tqdm(eval_dicts):\n",
    "            im = cv2.imread(e[\"file_name\"])\n",
    "            inputs = prepare_inputs(im, input_format, transform_gen)\n",
    "            outputs = model([inputs])[0]\n",
    "            outputs_bool = np.array(outputs['instances'].pred_masks.cpu()).sum(0) > 0\n",
    "            polygons = [np.array(a['segmentation'][0]) for a in e['annotations']]\n",
    "            if len(polygons) > 0:\n",
    "                targets_bool = polygons_to_bitmask(polygons, e['height'], e['width'])\n",
    "            else:\n",
    "                targets_bool = np.zeros((1024,1024)).astype(np.bool)\n",
    "\n",
    "            tps += outputs_bool[targets_bool].sum() if targets_bool.sum() > 0 else 0.\n",
    "            fns += targets_bool[~outputs_bool].sum() if (~outputs_bool).sum() > 0 else 0.\n",
    "            fps += (~targets_bool[outputs_bool]).sum() if outputs_bool.sum() > 0 else 0.\n",
    "    \n",
    "    rec = tps/(tps+fns)\n",
    "    pre = tps/(tps+fps)\n",
    "    metrics = {\n",
    "        'building:recall': rec,\n",
    "        'building:precision': pre,\n",
    "        'building:f1': 2*rec*pre/(rec+pre)\n",
    "    }\n",
    "    #wandb.log(metrics)\n",
    "    model = model.train()\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(dev_data, cfg, predictor.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "for d in random.sample(data_dicts, 3):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=metadata, scale=1.)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    display(Image.fromarray(vis.get_image()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
