{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torchvision.models.detection.backbone_utils import resnet, BackboneWithFPN, resnet_fpn_backbone\n",
    "from xv.nn.nets import BoxClassifier\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from xv import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/sky-eye/xv/io.py:34: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  _conf = yaml.load(file_path)\n"
     ]
    }
   ],
   "source": [
    "from xv.io import *\n",
    "conf = Config('config/config-damage-od.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2519/2519 [00:15<00:00, 161.40it/s]\n",
      "100%|██████████| 280/280 [00:01<00:00, 170.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/dev instances:  2017 224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader, dev_loader = io.get_damage_loaders(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_name = 'efficientnet-b0'\n",
    "encoder = smp.encoders.get_encoder(encoder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.ops.feature_pyramid_network.FeaturePyramidNetwork"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FeaturePyramidNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = (4,3,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32, 24, 40, 112]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeaturePyramidNetwork(in_channels_list, out_channels, extra_blocks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_shapes = smp.encoders.encoders[encoder_name]['out_shapes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import segmentation_models_pytorch as smp\n",
    "from collections import OrderedDict\n",
    "from torchvision.ops.feature_pyramid_network import FeaturePyramidNetwork\n",
    "\n",
    "class GeneralFPNBackbone(nn.Module):\n",
    "    def __init__(self, encoder_name, features = (4,3,2,1), out_channels=256):\n",
    "        super().__init__()\n",
    "        self.encoder = smp.encoders.get_encoder(encoder_name)\n",
    "        self.features = features\n",
    "        \n",
    "        out_shapes = smp.encoders.encoders[encoder_name]['out_shapes']\n",
    "        in_channels = [out_shapes[f] for f in features]\n",
    "        \n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = OrderedDict((i, x[i]) for i in self.features)\n",
    "        return self.fpn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = BoxClassifier(GeneralFPNBackbone(encoder_name), 4, featmap_names=(4,3,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    i,b,c = next(iter(dev_loader))\n",
    "    out = bc(i.cuda(), [bo.cuda() for bo in b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0470,  0.0478,  0.0043, -0.0298],\n",
       "        [ 0.0242,  0.0110,  0.0430, -0.0384],\n",
       "        [ 0.0206,  0.0490,  0.0186, -0.0313],\n",
       "        ...,\n",
       "        [-0.0411,  0.0157, -0.0054,  0.0054],\n",
       "        [ 0.0817,  0.0258,  0.0229, -0.0200],\n",
       "        [ 0.0403,  0.0015,  0.0563, -0.0272]], device='cuda:0')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from xv import io\n",
    "\n",
    "seg_run_id = \"qoijsx0h\"\n",
    "seg_run_path = f\"xvr-hlt/sky-eye-full/{seg_run_id}\"\n",
    "conf_file = wandb.restore('config.yaml', run_path=seg_run_path, replace=True).name\n",
    "state_file = wandb.restore('state_dict.pth', run_path=seg_run_path, replace=True).name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "dmg_run_id = \"zu0uhkyk\"\n",
    "dmg_run_path = f\"xvr-hlt/building-damage/{dmg_run_id}\"\n",
    "dmg_conf_file = wandb.restore('config.yaml', run_path=dmg_run_path, replace=True).name\n",
    "dmg_state_file = wandb.restore('state_dict.pth', run_path=dmg_run_path, replace=True).name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/sky-eye/xv/io.py:34: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  _conf = yaml.load(file_path)\n",
      "WARNING:root:Attribute freeze_backbone_norm not found in conf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "dmg_conf = Config(dmg_conf_file)\n",
    "dmg_model = io.load_damage_model(dmg_conf, dmg_state_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmg_model = dmg_model.eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xv.tta import BoxClassifierTTA\n",
    "\n",
    "dmg_model = BoxClassifierTTA(dmg_model)\n",
    "dmg_model = dmg_model.cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/56 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/56 [00:18<16:40, 18.20s/it]\u001b[A\n",
      "  4%|▎         | 2/56 [00:34<15:56, 17.72s/it]\u001b[A\n",
      "  5%|▌         | 3/56 [00:51<15:19, 17.35s/it]\u001b[A\n",
      "  7%|▋         | 4/56 [01:07<14:50, 17.13s/it]\u001b[A\n",
      "  9%|▉         | 5/56 [01:24<14:24, 16.94s/it]\u001b[A\n",
      " 11%|█         | 6/56 [01:40<13:59, 16.79s/it]\u001b[A\n",
      " 12%|█▎        | 7/56 [01:57<13:38, 16.70s/it]\u001b[A\n",
      " 14%|█▍        | 8/56 [02:13<13:18, 16.63s/it]\u001b[A\n",
      " 16%|█▌        | 9/56 [02:30<12:59, 16.57s/it]\u001b[A\n",
      " 18%|█▊        | 10/56 [02:46<12:43, 16.60s/it]\u001b[A\n",
      " 20%|█▉        | 11/56 [03:03<12:26, 16.60s/it]\u001b[A\n",
      " 21%|██▏       | 12/56 [03:20<12:09, 16.58s/it]\u001b[A\n",
      " 23%|██▎       | 13/56 [03:36<11:51, 16.54s/it]\u001b[A\n",
      " 25%|██▌       | 14/56 [03:52<11:33, 16.52s/it]\u001b[A\n",
      " 27%|██▋       | 15/56 [04:09<11:16, 16.51s/it]\u001b[A\n",
      " 29%|██▊       | 16/56 [04:25<11:00, 16.51s/it]\u001b[A\n",
      " 30%|███       | 17/56 [04:42<10:47, 16.60s/it]\u001b[A\n",
      " 32%|███▏      | 18/56 [04:59<10:29, 16.57s/it]\u001b[A\n",
      " 34%|███▍      | 19/56 [05:15<10:11, 16.53s/it]\u001b[A\n",
      " 36%|███▌      | 20/56 [05:32<09:55, 16.54s/it]\u001b[A\n",
      " 38%|███▊      | 21/56 [05:48<09:37, 16.51s/it]\u001b[A\n",
      " 39%|███▉      | 22/56 [06:05<09:20, 16.49s/it]\u001b[A\n",
      " 41%|████      | 23/56 [06:21<09:04, 16.49s/it]\u001b[A\n",
      " 43%|████▎     | 24/56 [06:38<08:48, 16.50s/it]\u001b[A\n",
      " 45%|████▍     | 25/56 [06:54<08:30, 16.48s/it]\u001b[A\n",
      " 46%|████▋     | 26/56 [07:11<08:15, 16.52s/it]\u001b[A\n",
      " 48%|████▊     | 27/56 [07:27<07:59, 16.52s/it]\u001b[A\n",
      " 50%|█████     | 28/56 [07:44<07:42, 16.53s/it]\u001b[A\n",
      " 52%|█████▏    | 29/56 [08:00<07:26, 16.52s/it]\u001b[A\n",
      " 54%|█████▎    | 30/56 [08:17<07:08, 16.50s/it]\u001b[A\n",
      " 55%|█████▌    | 31/56 [08:33<06:52, 16.52s/it]\u001b[A\n",
      " 57%|█████▋    | 32/56 [08:50<06:37, 16.54s/it]\u001b[A\n",
      " 59%|█████▉    | 33/56 [09:06<06:20, 16.53s/it]\u001b[A\n",
      " 61%|██████    | 34/56 [09:23<06:03, 16.54s/it]\u001b[A\n",
      " 62%|██████▎   | 35/56 [09:40<05:47, 16.56s/it]\u001b[A\n",
      " 64%|██████▍   | 36/56 [09:56<05:31, 16.58s/it]\u001b[A\n",
      " 66%|██████▌   | 37/56 [10:13<05:14, 16.56s/it]\u001b[A\n",
      " 68%|██████▊   | 38/56 [10:29<04:57, 16.54s/it]\u001b[A\n",
      " 70%|██████▉   | 39/56 [10:46<04:41, 16.56s/it]\u001b[A\n",
      " 71%|███████▏  | 40/56 [11:02<04:24, 16.52s/it]\u001b[A\n",
      " 73%|███████▎  | 41/56 [11:19<04:07, 16.50s/it]\u001b[A\n",
      " 75%|███████▌  | 42/56 [11:35<03:50, 16.48s/it]\u001b[A\n",
      " 77%|███████▋  | 43/56 [11:52<03:34, 16.52s/it]\u001b[A\n",
      " 79%|███████▊  | 44/56 [12:08<03:18, 16.50s/it]\u001b[A\n",
      " 80%|████████  | 45/56 [12:25<03:01, 16.49s/it]\u001b[A\n",
      " 82%|████████▏ | 46/56 [12:41<02:45, 16.53s/it]\u001b[A\n",
      " 84%|████████▍ | 47/56 [12:58<02:28, 16.52s/it]\u001b[A\n",
      " 86%|████████▌ | 48/56 [13:14<02:12, 16.57s/it]\u001b[A\n",
      " 88%|████████▊ | 49/56 [13:31<01:56, 16.61s/it]\u001b[A\n",
      " 89%|████████▉ | 50/56 [13:48<01:39, 16.57s/it]\u001b[A\n",
      " 91%|█████████ | 51/56 [14:04<01:22, 16.59s/it]\u001b[A\n",
      " 93%|█████████▎| 52/56 [14:21<01:06, 16.55s/it]\u001b[A\n",
      " 95%|█████████▍| 53/56 [14:37<00:49, 16.54s/it]\u001b[A\n",
      " 96%|█████████▋| 54/56 [14:54<00:33, 16.53s/it]\u001b[A\n",
      " 98%|█████████▊| 55/56 [15:10<00:16, 16.53s/it]\u001b[A\n",
      "100%|██████████| 56/56 [15:27<00:00, 16.56s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "from xv import run_damage\n",
    "dev_metrics = run_damage.evaluate(dmg_model, dev_loader, conf.nclasses, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': tensor(138.9520, device='cuda:0'),\n",
       " 'damage:categorical:0:precision': 0.9587116159780452,\n",
       " 'damage:categorical:0:recall': 0.9731051224975669,\n",
       " 'damage:categorical:0:f1': 0.9658547479429385,\n",
       " 'damage:categorical:1:precision': 0.7008871822300613,\n",
       " 'damage:categorical:1:recall': 0.5891278421648993,\n",
       " 'damage:categorical:1:f1': 0.640166425134305,\n",
       " 'damage:categorical:2:precision': 0.7955187922343381,\n",
       " 'damage:categorical:2:recall': 0.824661151116293,\n",
       " 'damage:categorical:2:f1': 0.8098278782317169,\n",
       " 'damage:categorical:3:precision': 0.8502461024329381,\n",
       " 'damage:categorical:3:recall': 0.8490813247001894,\n",
       " 'damage:categorical:3:f1': 0.8496633143771124,\n",
       " 'hmean:damage:categorical:precision': 0.815826867330693,\n",
       " 'hmean:damage:categorical:recall': 0.7819486526588151,\n",
       " 'hmean:damage:categorical:f1': 0.7985285939495259,\n",
       " 'mean:damage:categorical:precision': 0.8263409232188457,\n",
       " 'mean:damage:categorical:recall': 0.8089938601197372,\n",
       " 'mean:damage:categorical:f1': 0.8163780914215182}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([596, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.loss import CrossEntropyLoss\n",
    "\n",
    "weights = torch.Tensor(conf.class_weight).float().cuda()\n",
    "loss_fn = CrossEntropyLoss(weights, reduction=conf.loss_reduce_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:18<00:00,  3.09it/s]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': tensor(143.7780, device='cuda:0'),\n",
       " 'damage:categorical:0:precision': 0.9566251158974713,\n",
       " 'damage:categorical:0:recall': 0.9725116632441376,\n",
       " 'damage:categorical:0:f1': 0.9645029762757684,\n",
       " 'damage:categorical:1:precision': 0.6914017186737941,\n",
       " 'damage:categorical:1:recall': 0.5721420885855113,\n",
       " 'damage:categorical:1:f1': 0.6261437412790158,\n",
       " 'damage:categorical:2:precision': 0.7862104802696855,\n",
       " 'damage:categorical:2:recall': 0.8240910248303941,\n",
       " 'damage:categorical:2:f1': 0.8047052037966942,\n",
       " 'damage:categorical:3:precision': 0.8541146268856493,\n",
       " 'damage:categorical:3:recall': 0.8364122839403997,\n",
       " 'damage:categorical:3:f1': 0.8451707704212198,\n",
       " 'hmean:damage:categorical:precision': 0.8106345859347874,\n",
       " 'hmean:damage:categorical:recall': 0.7714377190617776,\n",
       " 'hmean:damage:categorical:f1': 0.7905505886059725,\n",
       " 'mean:damage:categorical:precision': 0.8220879854316501,\n",
       " 'mean:damage:categorical:recall': 0.8012892651501108,\n",
       " 'mean:damage:categorical:f1': 0.8101306729431745}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8c84bcca0434>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtta\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBoxClassifierTTA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdmg_model_tta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBoxClassifierTTA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdmg_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sky-eye/xv/tta.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mttach\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mBoxClassifierTTA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "from xv.tta import BoxClassifierTTA\n",
    "\n",
    "dmg_model_tta = BoxClassifierTTA(dmg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "i,b,c = next(iter(dev_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0136,  0.0353,  0.0300, -0.0351],\n",
       "        [-0.0268,  0.0461,  0.0141, -0.0433],\n",
       "        [-0.0027,  0.0448,  0.0089, -0.0444],\n",
       "        ...,\n",
       "        [-0.0289,  0.0241,  0.0323, -0.0026],\n",
       "        [-0.0144,  0.0195,  0.0299, -0.0213],\n",
       "        [-0.0103,  0.0369,  0.0282, -0.0394]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(i.cuda(),[bb.cuda() for bb in b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import wandb\n",
    "from glob import glob\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from xv.util import vis_im_mask\n",
    "from pprint import pprint\n",
    "import random\n",
    "from xv import dataset, io, run_damage\n",
    "import pandas as pd\n",
    "import random\n",
    "from pytorch_toolbelt import losses\n",
    "from torch.nn.modules.loss import CrossEntropyLoss\n",
    "from xv.nn.losses import loss_dict, WeightedLoss\n",
    "from torch.nn.modules.loss import CrossEntropyLoss\n",
    "from tqdm import tqdm as tqdm\n",
    "import pdb\n",
    "import logging\n",
    "from apex import amp\n",
    "\n",
    "os.environ['WANDB_MODE'] = 'dryrun'\n",
    "\n",
    "run_type = 'building-damage'\n",
    "conf_file = 'config/config-damage-od.yaml'\n",
    "\n",
    "wandb.init(project=run_type, config=yaml.load(open(conf_file)))\n",
    "conf = wandb.config\n",
    "pprint(dict(conf))\n",
    "\n",
    "train_loader, dev_loader = io.get_damage_loaders(conf)\n",
    "\n",
    "class MultiScaleResize(nn.Module):\n",
    "    def __init__(self, scales = (0.5, 0.75, 1.)):\n",
    "        super().__init__()\n",
    "        self.scales = scales\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def forward(self, x, boxes):\n",
    "        scale = random.choice(self.scales)\n",
    "        if scale != 1.:\n",
    "            x = torch.nn.functional.interpolate(x, scale_factor=scale, mode='bilinear', align_corners=False)\n",
    "            boxes = [b*scale for b in boxes]\n",
    "        return x, boxes\n",
    "\n",
    "train_resize = MultiScaleResize(conf.training_scales)\n",
    "\n",
    "model = io.load_damage_model(conf)\n",
    "model = model.cuda()\n",
    "\n",
    "optims = {'adam': torch.optim.Adam}\n",
    "optim = optims[conf.optim](model.parameters(), lr=conf.lr)\n",
    "\n",
    "model, optim = amp.initialize(model, optim, opt_level=conf.amp_opt_level)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optim, factor=conf.scheduler_factor, patience=conf.scheduler_patience\n",
    ")\n",
    "\n",
    "#loss_fn = WeightedLoss({loss_dict[l]():w for l, w in conf.loss_weights.items()})\n",
    "#loss_fn = losses.JaccardLoss('multiclass')\n",
    "#loss_fn = CrossEntropyLoss(weights)\n",
    "\n",
    "#loss_fn = losses.JointLoss(loss_fn, losses.FocalLoss(), 0.5, 0.5)\n",
    "\n",
    "\n",
    "epoch, best_score = 0, 0\n",
    "\n",
    "\n",
    "for epoch in range(epoch, conf.epochs):\n",
    "    metrics = {'epoch': epoch}\n",
    "    train_metrics = run_damage.run(model, optim, train_loader, train_resize, loss_fn)\n",
    "    metrics.update(train_metrics)\n",
    "    \n",
    "    \n",
    "    metrics.update(dev_metrics)\n",
    "    \n",
    "    wandb.log(metrics)\n",
    "    scheduler.step(metrics['loss'])\n",
    "    score = metrics[conf.metric]\n",
    "    \n",
    "    if score > best_score:\n",
    "        torch.save(model.state_dict(), os.path.join(wandb.run.dir, \"state_dict.pth\"))\n",
    "        best_score = score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im, boxes, clss = train_loader.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ttach import functional as tF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tF.rot90(torch.Tensor(im)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xv.io import load_dmg_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dmg_img??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
