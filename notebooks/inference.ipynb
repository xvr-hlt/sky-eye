{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "api = wandb.Api()\n",
    "def get_score(r, metric):\n",
    "    hist = list(r.scan_history())\n",
    "    scores = [h[METRIC] for h in hist if METRIC in h]\n",
    "    if not scores: return None\n",
    "    return max(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from xv import io\n",
    "from xv.io import Config\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmg_is_seg = True\n",
    "\n",
    "seg_run_id = \"qoijsx0h\"\n",
    "dmg_run_id = \"0gvvydkt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "test_dir = '../../datasets/xview/test'\n",
    "submission_dir = f\"../submissions/{seg_run_id}_{dmg_run_id}_{str(datetime.now()).replace(' ', '_').replace(':', '-')}\"\n",
    "\n",
    "cache_dir = f'../submissions/cache/{seg_run_id}'\n",
    "os.mkdir(submission_dir)\n",
    "print(submission_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ttach as tta\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "USE_CACHED_SEG = True\n",
    "CACHE_SEG = False\n",
    "\n",
    "if USE_CACHED_SEG:\n",
    "    assert os.path.isdir(cache_dir)\n",
    "    !cp {cache_dir}/* {submission_dir}\n",
    "    \n",
    "else:\n",
    "    if CACHE_SEG:\n",
    "        if os.path.isdir(cache_dir):\n",
    "            shutil.rmtree(cache_dir)\n",
    "        os.mkdir(cache_dir)\n",
    "\n",
    "    seg_run_path = f\"xvr-hlt/sky-eye-full/{seg_run_id}\"\n",
    "    conf_file = wandb.restore('config.yaml', run_path=seg_run_path, replace=True).name\n",
    "    state_file = wandb.restore('state_dict.pth', run_path=seg_run_path, replace=True).name\n",
    "\n",
    "    conf = Config(conf_file)\n",
    "    model, preprocess_fn = io.load_segmentation_model(conf, state_file)\n",
    "    model = model.eval().cuda()\n",
    "    model = tta.SegmentationTTAWrapper(model, tta.aliases.d4_transform(), merge_mode='mean')\n",
    "    pre_files = glob(f\"{test_dir}/images/*pre*\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for f in tqdm(pre_files):\n",
    "            i = io.load_img(f, preprocess_fn)\n",
    "            out = model(i.cuda())[0][0] > 0.\n",
    "            out = out.cpu().numpy().astype(np.uint8)\n",
    "            fid = f.split('_')[-1].replace(\".png\", \"\")\n",
    "            Image.fromarray(out).save(f\"{submission_dir}/test_localization_{fid}_prediction.png\")\n",
    "            if CACHE_SEG:\n",
    "                Image.fromarray(out).save(f\"{cache_dir}/test_localization_{fid}_prediction.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xv.tta import BoxClassifierTTA\n",
    "import ttach as tta\n",
    "\n",
    "if dmg_is_seg:\n",
    "    dmg_run_path = f\"xvr-hlt/building-seg-damage/{dmg_run_id}\"\n",
    "else:\n",
    "    dmg_run_path = f\"xvr-hlt/building-damage/{dmg_run_id}\"\n",
    "\n",
    "dmg_conf_file = wandb.restore('config.yaml', run_path=dmg_run_path, replace=True).name\n",
    "dmg_state_file = wandb.restore('state_dict.pth', run_path=dmg_run_path, replace=True).name\n",
    "\n",
    "dmg_conf = Config(dmg_conf_file)\n",
    "\n",
    "if dmg_is_seg:\n",
    "    dmg_model, dmg_preprocess_fn = io.load_segmentation_model(dmg_conf, dmg_state_file)\n",
    "    dmg_model = tta.SegmentationTTAWrapper(dmg_model, tta.aliases.d4_transform(), merge_mode='mean')\n",
    "else:\n",
    "    dmg_model = io.load_damage_model(dmg_conf, dmg_state_file)\n",
    "    dmg_model = BoxClassifierTTA(dmg_model)\n",
    "    \n",
    "dmg_model = dmg_model.eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from imantics import Polygons\n",
    "\n",
    "post_files = glob(f\"{test_dir}/images/*post*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_box_damage(dmg_model, inp_file, mask_file):\n",
    "    msk_dmg = np.zeros((1024, 1024), dtype=np.uint8)\n",
    "    \n",
    "    msk = np.array(Image.open(mask_file))\n",
    "\n",
    "    polys = Polygons.from_mask(msk)\n",
    "    polypoints = polys.points\n",
    "    \n",
    "    if not polypoints:\n",
    "        return Image.fromarray(msk_dmg)\n",
    "    \n",
    "    inp = io.load_dmg_img(inp_file)\n",
    "    boxes = torch.Tensor([[min(p[:,0]), min(p[:,1]), max(p[:,0]), max(p[:,1])] for p in polypoints])\n",
    "    out = dmg_model(inp.cuda(), [boxes.cuda()])\n",
    "    classes = (out.argmax(1) + 1).cpu().numpy()\n",
    "\n",
    "    for poly, cls in zip(polypoints, classes):\n",
    "        cv2.fillPoly(msk_dmg, [poly], int(cls))\n",
    "\n",
    "    return Image.fromarray(msk_dmg)\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_seg_damage(dmg_model, preprocess_fn, inp_file, mask_file):\n",
    "    inp = io.load_img(f, dmg_preprocess_fn)\n",
    "    out = dmg_model(inp.cuda())[0]\n",
    "    out = (out.argmax(0) + 1).cpu().numpy()\n",
    "    return Image.fromarray(out.astype(np.uint8))\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_seg_damage(dmg_model, preprocess_fn, inp_file, mask_file):\n",
    "    mb = np.array(Image.open(mask_file))\n",
    "    inp = io.load_img(f, dmg_preprocess_fn)\n",
    "    out = dmg_model(inp.cuda())[0]\n",
    "    \n",
    "    out = out.sigmoid()/out.sigmoid().sum(0)\n",
    "    out = out.cpu().numpy()\n",
    "    \n",
    "    damage_map = np.zeros((1024,1024))\n",
    "    \n",
    "    for poly in Polygons.from_mask(mb):\n",
    "        poly_mask = Polygons.create([poly]).mask(1024, 1024).array\n",
    "        cls = out[:,poly_mask].mean(1).argmax() + 1\n",
    "        damage_map[poly_mask] = cls\n",
    "    \n",
    "    return Image.fromarray(damage_map.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in tqdm(post_files):\n",
    "    fid = f.split('_')[-1].replace(\".png\", \"\")\n",
    "    mask_file = f\"{submission_dir}/test_localization_{fid}_prediction.png\"\n",
    "    \n",
    "    if dmg_is_seg:\n",
    "        img = get_seg_damage(dmg_model, dmg_preprocess_fn, f, mask_file)\n",
    "    else:\n",
    "        img = get_box_damage(dmg_model, f, mask_file)\n",
    "\n",
    "    img.save(f\"{submission_dir}/test_damage_{fid}_prediction.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_split = submission_dir.rfind('/') + 1\n",
    "root, subdir = submission_dir[:_split], submission_dir[_split:]\n",
    "\n",
    "! cd \"{root}\" && zip -r \"{subdir}.zip\" \"{subdir}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm config.yaml state_dict.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
