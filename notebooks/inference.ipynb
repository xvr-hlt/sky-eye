{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "test_dir = '../../datasets/xview/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "submission_dir = f\"../submissions/{str(datetime.now()).replace(' ', '_').replace(':', '-')}\"\n",
    "os.mkdir(submission_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "class Config:\n",
    "    def __init__(self, file_path, file_type='json'):\n",
    "        with open(file_path) as f:\n",
    "            if file_path.endswith('.json'):\n",
    "                _conf = json.load(f)\n",
    "            elif file_path.endswith('.yaml'):\n",
    "                _conf = yaml.load(f)\n",
    "        for k,v in _conf.items():\n",
    "            setattr(self, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "from xv.nn.layers import FrozenBatchNorm2d\n",
    "\n",
    "def load_segmentation_model(conf_file, state_file):\n",
    "    conf = Config(conf_file)\n",
    "\n",
    "    segmentation_types = {\n",
    "        'PSPNet': smp.PSPNet,\n",
    "        'FPN': smp.FPN,\n",
    "        'Linknet': smp.Linknet,\n",
    "        'Unet': smp.Unet\n",
    "    }\n",
    "\n",
    "    model_classes = conf.nclasses\n",
    "\n",
    "    model = segmentation_types[conf.segmentation_arch](\n",
    "        conf.encoder,\n",
    "        classes=model_classes,\n",
    "        activation='sigmoid',\n",
    "        attention_type=conf.attention\n",
    "    )\n",
    "\n",
    "\n",
    "    if conf.freeze_encoder_norm:\n",
    "        model.encoder = FrozenBatchNorm2d.convert_frozen_batchnorm(model.encoder)\n",
    "\n",
    "    if conf.freeze_decoder_norm:\n",
    "        model.decoder = FrozenBatchNorm2d.convert_frozen_batchnorm(model.decoder)\n",
    "\n",
    "    preprocess_fn = get_preprocessing_fn(conf.encoder)\n",
    "\n",
    "    state_dict = torch.load(state_file)\n",
    "\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model, preprocess_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_file = \"../weights/b-run-20191115_213743-qoijsx0h/conf.json\"\n",
    "state_file = \"../weights/b-run-20191115_213743-qoijsx0h/state_dict.pth\"\n",
    "\n",
    "model, preprocess_fn = load_segmentation_model(conf_file, state_file)\n",
    "model = model.eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ttach as tta\n",
    "model = tta.SegmentationTTAWrapper(model, tta.aliases.d4_transform(), merge_mode='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "pre_files = glob(f\"{test_dir}/images/*pre*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def load_img(img_path, preprocess_fn):\n",
    "    image = np.array(Image.open(img_path))\n",
    "    image = preprocess_fn(image)\n",
    "    image = image.transpose(2,0,1)\n",
    "    image = image.astype(np.float32)\n",
    "    return torch.Tensor(image[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for f in tqdm(pre_files):\n",
    "        i = load_img(f, preprocess_fn)\n",
    "        out = model(i.cuda())[0][0] > 0\n",
    "        out = out.cpu().numpy().astype(np.uint8)\n",
    "        fid = f.split('_')[-1].replace(\".png\", \"\")\n",
    "        Image.fromarray(out).save(f\"{submission_dir}/test_localization_{fid}_prediction.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xv.nn.nets import BoxClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmg_conf_file = \"../weights/rcndcpcc/config-damage-od.yaml\"\n",
    "dmg_state_file = \"../weights/rcndcpcc/state_dict.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "\n",
    "def load_damage_model(conf_file, state_file):\n",
    "    conf = Config(conf_file)\n",
    "    backbone = resnet_fpn_backbone(conf.backbone, True)\n",
    "    model = BoxClassifier(backbone, conf.nclasses)\n",
    "    state_dict = torch.load(state_file)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model = model.eval().cuda()\n",
    "    return model\n",
    "\n",
    "def load_dmg_img(img_path, image_mean = (0.485, 0.456, 0.406), image_std = (0.229, 0.224, 0.225)):\n",
    "    image = np.array(Image.open(img_path))\n",
    "    image = image.astype(np.float32)\n",
    "    image /= 255.\n",
    "    image = (image-image_mean)/image_std\n",
    "    image = image.transpose(2,0,1)\n",
    "    return torch.Tensor(image[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_files = glob(f\"{test_dir}/images/*post*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imantics import Polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmg_model = load_damage_model(dmg_conf_file, dmg_state_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "for f in tqdm(post_files):\n",
    "    fid = f.split('_')[-1].replace(\".png\", \"\")\n",
    "    mask_file = f\"{submission_dir}/test_localization_{fid}_prediction.png\"\n",
    "    msk = np.array(Image.open(mask_file))\n",
    "    polys = Polygons.from_mask(msk)\n",
    "    \n",
    "    polypoints = polys.points\n",
    "    if polypoints:\n",
    "        with torch.no_grad():\n",
    "            boxes = torch.Tensor([[min(p[:,0]), min(p[:,1]), max(p[:,0]), max(p[:,1])] for p in polypoints])\n",
    "            inp = load_dmg_img(f)\n",
    "            out = dmg_model(inp.cuda(), [boxes.cuda()])\n",
    "            classes = (out.argmax(1) + 1).cpu().numpy()\n",
    "    else:\n",
    "        classes = []\n",
    "\n",
    "    msk_dmg = np.zeros((1024, 1024), dtype=np.uint8)\n",
    "    \n",
    "    for poly, cls in zip(polypoints, classes):\n",
    "        cv2.fillPoly(msk_dmg, [poly], int(cls))\n",
    "\n",
    "    Image.fromarray(msk_dmg).save(f\"{submission_dir}/test_damage_{fid}_prediction.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_split = submission_dir.rfind('/') + 1\n",
    "root, subdir = submission_dir[:_split], submission_dir[_split:]\n",
    "\n",
    "! cd \"{root}\" && zip -r \"{subdir}.zip\" \"{subdir}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
