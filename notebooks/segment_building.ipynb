{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "import os\n",
    "import wandb\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_file = \"config/config-seg.yaml\"\n",
    "# conf_file = \"config/config-seg-finetune.yaml\"\n",
    "# conf_file = \"config/config-seg-joint.yaml\"\n",
    "\n",
    "with open(conf_file) as f:\n",
    "    conf_init = yaml.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'tertiary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['WANDB_MODE'] = 'dryrun'\n",
    "wandb.init(project=conf_init['project'], config=conf_init, name=name)\n",
    "conf = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(dict(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from xv.util import vis_im_mask\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../../datasets/xview/train'\n",
    "test_dir = '../../datasets/xview/test'\n",
    "suppl_dir = '../../datasets/xview/tier3'\n",
    "tertiary_dir = '../../datasets/spacenet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as al\n",
    "\n",
    "augment = al.Compose([\n",
    "        al.HorizontalFlip(p=conf.aug_prob),\n",
    "        al.VerticalFlip(p=conf.aug_prob),\n",
    "        al.RandomRotate90(p=conf.aug_prob),\n",
    "        al.Transpose(p=conf.aug_prob),\n",
    "        al.GridDistortion(p=conf.aug_prob, distort_limit=.2),\n",
    "        al.ShiftScaleRotate(p=conf.aug_prob),\n",
    "        al.RandomBrightnessContrast(p=conf.aug_prob),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "segmentation_types = {\n",
    "    'PSPNet': smp.PSPNet,\n",
    "    'FPN': smp.FPN,\n",
    "    'Linknet': smp.Linknet,\n",
    "    'Unet': smp.Unet\n",
    "}\n",
    "\n",
    "model_classes = conf.nclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualWrapper(nn.Module):\n",
    "    def __init__(self, m, channels_in=16):\n",
    "        super().__init__()\n",
    "        self._model = m\n",
    "        \n",
    "        self.pre_mixin = nn.Sequential(\n",
    "            nn.Conv2d(channels_in, channels_in, kernel_size=1),\n",
    "            nn.BatchNorm2d(channels_in),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.post_mixin = nn.Sequential(\n",
    "            nn.Conv2d(channels_in, channels_in, kernel_size=1),\n",
    "            nn.BatchNorm2d(channels_in),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pre, post = x[:,:3], x[:,3:]\n",
    "        \n",
    "        pre_out = self.pre_mixin(self._model.decoder(*self._model.encoder(pre)))\n",
    "        post_out = self.post_mixin(self._model.decoder(*self._model.encoder(post)))\n",
    "        \n",
    "        return self._model.segmentation_head(pre_out + post_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xv.nn.layers import FrozenBatchNorm2d\n",
    "\n",
    "model = segmentation_types[conf.segmentation_arch](\n",
    "    conf.encoder,\n",
    "    classes=model_classes,\n",
    "    decoder_attention_type=conf.attention,\n",
    ")\n",
    "\n",
    "if conf.mode == \"dual\":\n",
    "    model = DualWrapper(model)\n",
    "\n",
    "if conf.load_weights:\n",
    "    state_dict = torch.load(conf.load_weights)\n",
    "    print(model.load_state_dict(state_dict))\n",
    "\n",
    "preprocess_fn = get_preprocessing_fn(conf.encoder)\n",
    "\n",
    "if conf.freeze_encoder_norm:\n",
    "    model.encoder = FrozenBatchNorm2d.convert_frozen_batchnorm(model.encoder)\n",
    "    \n",
    "if conf.freeze_decoder_norm:\n",
    "    model.decoder = FrozenBatchNorm2d.convert_frozen_batchnorm(model.decoder)\n",
    "    \n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xv.nn.oc import oc\n",
    "\n",
    "class OCSegment(nn.Module):\n",
    "    def __init__(self, model, decoder_channels=128):\n",
    "        super().__init__()\n",
    "        self._model = model\n",
    "        self.context = oc.InterlacedSparseSelfAttention(decoder_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self._model.encoder(x)\n",
    "        out = self._model.decoder(*features)\n",
    "        out = self.context(out)\n",
    "        return self._model.segmentation_head(out)\n",
    "        \n",
    "        \n",
    "#model = OCSegment(model).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from xv import dataset\n",
    "import pandas as pd\n",
    "\n",
    "train_stems = pd.read_csv('config/train_stems.csv', header=None)[0]\n",
    "dev_stems = pd.read_csv('config/dev_stems.csv', header=None)[0]\n",
    "\n",
    "train_files = [f'{train_dir}/labels/{stem}_{conf.data_prefix}_disaster.json' for stem in train_stems]\n",
    "dev_files = [f'{train_dir}/labels/{stem}_{conf.data_prefix}_disaster.json' for stem in dev_stems]\n",
    "\n",
    "train_instances = dataset.get_instances(train_files, filter_none=conf.filter_none)\n",
    "dev_instances = dataset.get_instances(dev_files, filter_none=conf.filter_none)\n",
    "\n",
    "len(train_instances), len(dev_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if conf.add_suppl:\n",
    "    train_instances *= conf.train_repeat\n",
    "    suppl_files = glob(f'{suppl_dir}/labels/*{conf.data_prefix}_disaster.json')\n",
    "    suppl_instances = dataset.get_instances(suppl_files, filter_none=conf.filter_none)\n",
    "    train_instances += suppl_instances\n",
    "    print(len(train_instances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if conf.add_tertiary:\n",
    "    import pandas as pd\n",
    "    from PIL import Image\n",
    "    import shapely\n",
    "    tertiary_instances = []\n",
    "\n",
    "    for subdir in tqdm(os.listdir(tertiary_dir)):\n",
    "        csv = glob(f'{tertiary_dir}/{subdir}/summaryData/*.csv')[0]    \n",
    "        df = pd.read_csv(csv)\n",
    "        for img, group in tqdm(df.groupby('ImageId')):\n",
    "            filepath = f'{tertiary_dir}/{subdir}/rgb/rgb_{img}.jpg'\n",
    "            _im = Image.open(filepath)\n",
    "            h,w = _im.size\n",
    "            polys = [shapely.wkt.loads(p) for p in group.PolygonWKT_Pix]\n",
    "            points_list = [list(poly.exterior.coords) for poly in polys if poly.exterior is not None]\n",
    "            points_list = [[(x/w, y/h) for x,y,_ in points] for points in points_list]\n",
    "            annotations = []\n",
    "            for points in points_list:\n",
    "                x,y = zip(*points)\n",
    "                annotations.append({\n",
    "                    'bbox':[(min(x), min(y)), (max(x), max(y))],\n",
    "                    'bbox_mode': None,\n",
    "                    'segmentation': points,\n",
    "                    'category_id': 0,\n",
    "                    'iscrowd': 0  \n",
    "                })\n",
    "\n",
    "            tertiary_instances.append({\n",
    "                'height': h,\n",
    "                'width': w,\n",
    "                'file_name': filepath,\n",
    "                'annotations': annotations,\n",
    "            })\n",
    "    train_instances += tertiary_instances\n",
    "    print(len(train_instances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_toolbelt import losses\n",
    "from xv.nn.losses import loss_dict, WeightedLoss\n",
    "from torch.nn.modules.loss import CrossEntropyLoss\n",
    "loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xv.nn.losses import loss_dict, WeightedLoss\n",
    "from torch.nn.modules.loss import CrossEntropyLoss\n",
    "\n",
    "if 'class_weight' in dict(conf):\n",
    "    weights = torch.Tensor(conf.class_weight).float().cuda()\n",
    "    loss = CrossEntropyLoss(weights)\n",
    "else:\n",
    "    loss = WeightedLoss({loss_dict[l]():w for l, w in conf.loss_weights.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apex\n",
    "\n",
    "optims = {\n",
    "    'adam': torch.optim.Adam,\n",
    "    'sgd': torch.optim.SGD\n",
    "}\n",
    "\n",
    "optim = optims[conf.optim](model.parameters(), lr=conf.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xv import dataset\n",
    "train_dataset = dataset.BuildingSegmentationDataset(\n",
    "    instances=train_instances,\n",
    "    nclasses=conf.nclasses,\n",
    "    resolution=conf.training_resolution,\n",
    "    augment=augment,\n",
    "    preprocess_fn=preprocess_fn,\n",
    "    mode=conf.mode,\n",
    ")\n",
    "\n",
    "dev_dataset = dataset.BuildingSegmentationDataset(\n",
    "    instances=dev_instances,\n",
    "    nclasses=conf.nclasses,\n",
    "    resolution=conf.training_resolution,\n",
    "    augment=None,\n",
    "    preprocess_fn=preprocess_fn,\n",
    "    mode=conf.mode,\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=conf.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=10,\n",
    ")\n",
    "\n",
    "dev_loader = torch.utils.data.DataLoader(\n",
    "    dev_dataset,\n",
    "    batch_size=conf.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apex import amp\n",
    "model, optim = amp.initialize(model, optim, opt_level=conf.amp_opt_level);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optim, factor=conf.scheduler_factor, patience=conf.scheduler_patience\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.ops import misc as misc_nn_ops\n",
    "import random\n",
    "\n",
    "class MultiScaleResize(nn.Module):\n",
    "    def __init__(self, mode=\"categorical\", scales = (0.5, 0.75, 1.)):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.scales = scales\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def forward(self, batch):\n",
    "        scale = random.choice(self.scales)\n",
    "        if scale == 1.:\n",
    "            return batch\n",
    "        if self.mode is None or self.mode == \"dual\":\n",
    "            im, mask = batch\n",
    "            mask_dtype = mask.dtype\n",
    "            im = torch.nn.functional.interpolate(im, scale_factor=scale, mode='bilinear', align_corners=False)\n",
    "            mask = misc_nn_ops.interpolate(mask.float(), scale_factor=scale).to(mask_dtype)\n",
    "            return im, mask\n",
    "        if self.mode == \"categorical\":\n",
    "            im, (damage_mask, damage) = batch\n",
    "            dmg_msk_dtype = damage_mask.dtype()\n",
    "            dmg_dtype = damage.dtype()\n",
    "            im = torch.nn.functional.interpolate(im, scale_factor=scale, mode='bilinear', align_corners=False)\n",
    "            damage_mask = misc_nn_ops.interpolate(damage_mask[None].float(), scale_factor=scale)[0].to(dmg_msk_dtype)\n",
    "            damage_one_hot = torch.nn.functional.one_hot(damage).permute(0,3,1,2)\n",
    "            damage = misc_nn_ops.interpolate(damage_one_hot.float(), scale_factor=scale).argmax(1)\n",
    "            return im, (damage_mask, damage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_resize = MultiScaleResize(conf.mode, conf.training_scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xv import run\n",
    "\n",
    "train_fn = run.train_segment if conf.nclasses == 1 else run.train_damage\n",
    "eval_fn = run.evaluate_segment if conf.nclasses == 1 else run.evaluate_damage\n",
    "\n",
    "for epoch in range(epoch, conf.epochs):\n",
    "    metrics = {'epoch': epoch}\n",
    "    train_metrics = train_fn(model, optim, train_loader, loss, train_resize=train_resize, mode=conf.mode)\n",
    "    metrics.update(train_metrics)\n",
    "    \n",
    "    dev_metrics = eval_fn(model, dev_loader, loss, mode=conf.mode)\n",
    "    metrics.update(dev_metrics)\n",
    "    \n",
    "    if conf.mode != \"dual\":\n",
    "        examples = run.sample_masks(model, dev_instances, preprocess_fn, n=3)\n",
    "        metrics['examples'] = [wandb.Image(im, caption=f'mask:{ix}') for e in examples for ix, im in enumerate(e)]\n",
    "    \n",
    "    wandb.log(metrics)\n",
    "    scheduler.step(metrics['loss'])\n",
    "    score = metrics[conf.metric]\n",
    "\n",
    "    if score > best_score:\n",
    "        torch.save(model.state_dict(), os.path.join(wandb.run.dir, \"state_dict.pth\"))\n",
    "        best_score = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    rundir = 'b-' + wandb.run.dir.split('/')[-1]\n",
    "    !mkdir ../weights/{rundir}\n",
    "    !cp {os.path.join(wandb.run.dir, \"state_dict.pth\")}  ../weights/{rundir}\n",
    "    import json\n",
    "    with open(f'../weights/{rundir}/conf.json', 'w') as f:\n",
    "        json.dump(dict(conf), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],

   "source": [
    "print(rundir)\n",
    "!ls -lah ../weights/{rundir}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
