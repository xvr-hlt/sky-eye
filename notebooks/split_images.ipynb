{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../../datasets/xview/train'\n",
    "test_dir = '../../datasets/xview/test'\n",
    "suppl_dir = '../../datasets/xview/tier3'\n",
    "tertiary_dir = '../../datasets/spacenet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xv.dataset import get_instances, get_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2799/2799 [00:27<00:00, 103.03it/s]\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "files = glob(train_dir + '/labels/*pre_disaster.json')\n",
    "instances = get_instances(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def split_save(instance):\n",
    "    image = np.array(Image.open(instance['file_name']))\n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    polys = [a['segmentation'] for a in instance['annotations']]\n",
    "    msk = get_mask(polys, w, h)\n",
    "\n",
    "    hm, wm = h//2, w//2\n",
    "    split_im = image[:hm, :wm], image[:hm, wm:], image[hm:, :wm], image[hm:, wm:]\n",
    "    split_msk = msk[:hm, :wm], msk[:hm, wm:], msk[hm:, :wm], msk[hm:, wm:]\n",
    "\n",
    "    base_img_path = instance['file_name'].replace('images', 'images_split')\n",
    "    base_msk_path = instance['file_name'].replace('images', 'masks_split').replace('png', 'npy')\n",
    "\n",
    "    for ix, (i, m) in enumerate(zip(split_im, split_msk)):\n",
    "        Image.fromarray(i).save(base_img_path.replace('pre_disaster', f'{ix}_pre_disaster'))\n",
    "        np.save(base_msk_path.replace('pre_disaster', f'{ix}_pre_disaster'), m)\n",
    "        \n",
    "len(instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xv import run\n",
    "from torchvision.ops import misc as misc_nn_ops\n",
    "from apex import amp\n",
    "from torch.nn.modules.loss import CrossEntropyLoss\n",
    "from xv.nn.losses import loss_dict, WeightedLoss\n",
    "from pytorch_toolbelt import losses\n",
    "import pandas as pd\n",
    "from xv import dataset\n",
    "import random\n",
    "from xv.nn.layers import FrozenBatchNorm2d\n",
    "from xv.util import vis_im_mask\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "import os\n",
    "import wandb\n",
    "import yaml\n",
    "from xv import io\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "#conf_file = \"config/config-seg.yaml\"\n",
    "conf_file = \"config/config-damage.yaml\"\n",
    "# conf_file = \"config/config-seg-finetune.yaml\"\n",
    "# conf_file = \"config/config-seg-joint.yaml\"\n",
    "\n",
    "with open(conf_file) as f:\n",
    "    conf_init = yaml.load(f)\n",
    "\n",
    "#os.environ['WANDB_MODE'] = 'dryrun'\n",
    "wandb.init(project=conf_init['project'], config=conf_init, name=conf_init['name'])\n",
    "conf = wandb.config\n",
    "\n",
    "pprint(dict(conf))\n",
    "\n",
    "model, preprocess_fn = io.load_segmentation_model(conf)\n",
    "    \n",
    "model.to('cuda')\n",
    "\n",
    "train_dataset, train_loader = io.load_training_data(conf, preprocess_fn)\n",
    "dev_dataset, dev_loader = io.load_dev_data(conf, preprocess_fn)\n",
    "\n",
    "print(f\"n_train: {len(train_dataset)}\")\n",
    "print(f\"n_dev: {len(dev_dataset)}\")\n",
    "\n",
    "weights = torch.Tensor(conf.class_weight).float().cuda()\n",
    "loss = CrossEntropyLoss(weights, reduction=conf.loss_reduce_mode)\n",
    "\n",
    "\n",
    "#loss = WeightedLoss({loss_dict[l](): w for l, w in conf.loss_weights.items()})\n",
    "\n",
    "optims = {\n",
    "    'adam': torch.optim.Adam,\n",
    "    'sgd': torch.optim.SGD\n",
    "}\n",
    "\n",
    "optim = optims[conf.optim](model.parameters(), lr=conf.lr)\n",
    "\n",
    "\n",
    "model, optim = amp.initialize(model, optim, opt_level=conf.amp_opt_level)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    #if conf.sync_bn:\n",
    "    #    model = nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "    model = nn.DataParallel(model)\n",
    "    #torch.distributed.init_process_group(backend=\"nccl\")\n",
    "    #model = nn.DistributedDataParallel(model)\n",
    "\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optim, factor=conf.scheduler_factor, patience=conf.scheduler_patience\n",
    ")\n",
    "\n",
    "train_resize = run.MultiScaleResize(conf.mode, conf.training_scales)\n",
    "\n",
    "best_score = 0\n",
    "epoch = 0\n",
    "\n",
    "\n",
    "train_fn = run.train_segment if conf.nclasses == 1 else run.train_damage\n",
    "eval_fn = run.evaluate_segment if conf.nclasses == 1 else run.evaluate_damage\n",
    "\n",
    "for epoch in range(epoch, conf.epochs):\n",
    "    print(f\"epoch {epoch}/{conf.epochs}.\")\n",
    "    torch.save(optim.state_dict(), os.path.join(wandb.run.dir, \"optim.pth\"))\n",
    "    torch.save(scheduler.state_dict(), os.path.join(wandb.run.dir, \"scheduler.pth\"))\n",
    "    metrics = {'epoch': epoch}\n",
    "    train_metrics = train_fn(model, optim, train_loader, loss, train_resize=train_resize, mode=conf.mode)\n",
    "    metrics.update(train_metrics)\n",
    "\n",
    "    dev_metrics = eval_fn(model, dev_loader, loss, mode=conf.mode)\n",
    "    metrics.update(dev_metrics)\n",
    "    \n",
    "    \"\"\"\n",
    "    if conf.mode != \"dual\":\n",
    "        examples = run.sample_masks(model, dev_dataset.instances, preprocess_fn, n=1)\n",
    "        metrics['examples'] = [wandb.Image(im, caption=f'mask:{ix}') for e in examples for ix, im in enumerate(e)]\n",
    "    \"\"\"\n",
    "    \n",
    "    wandb.log(metrics)\n",
    "    score = metrics[conf.metric]\n",
    "    scheduler.step(-score)\n",
    "    pprint(metrics)\n",
    "    if score > best_score:\n",
    "        torch.save(model.state_dict(), os.path.join(wandb.run.dir, \"state_dict.pth\"))\n",
    "        best_score = score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
